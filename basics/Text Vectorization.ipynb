{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To apply any text featurization first we need to convert the raw data into meaningful data which is known as text preprocessing.\n",
    "\n",
    "**Pre-processing steps include**\n",
    "- Removing Noisy Data\n",
    "- Tokenization\n",
    "- Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/maria/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.datasets import load_files\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import pickle\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34552974</td>\n",
       "      <td>How to get all the child records from differen...</td>\n",
       "      <td>I am having 4 different tables like \\r\\nselect...</td>\n",
       "      <td>&lt;sql&gt;&lt;sql-server&gt;</td>\n",
       "      <td>2016-01-01 01:44:52</td>\n",
       "      <td>LQ_EDIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34554721</td>\n",
       "      <td>Retrieve all except some data of the another t...</td>\n",
       "      <td>I have two table m_master and tbl_appointment\\...</td>\n",
       "      <td>&lt;php&gt;&lt;mysql&gt;&lt;sql&gt;&lt;codeigniter&gt;&lt;mysqli&gt;</td>\n",
       "      <td>2016-01-01 08:43:50</td>\n",
       "      <td>LQ_EDIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34555135</td>\n",
       "      <td>Pandas: read_html</td>\n",
       "      <td>&lt;p&gt;I'm trying to extract US states from wiki U...</td>\n",
       "      <td>&lt;python&gt;&lt;pandas&gt;</td>\n",
       "      <td>2016-01-01 09:55:22</td>\n",
       "      <td>HQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34555448</td>\n",
       "      <td>Reader Always gimme NULL</td>\n",
       "      <td>I'm so new to C#, I wanna make an application ...</td>\n",
       "      <td>&lt;sql-server&gt;&lt;c#-4.0&gt;</td>\n",
       "      <td>2016-01-01 10:43:45</td>\n",
       "      <td>LQ_EDIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34555752</td>\n",
       "      <td>php rearrange array elements based on condition</td>\n",
       "      <td>basically i have this array:\\r\\n\\r\\n    array(...</td>\n",
       "      <td>&lt;php&gt;</td>\n",
       "      <td>2016-01-01 11:34:09</td>\n",
       "      <td>LQ_EDIT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                              Title  \\\n",
       "0  34552974  How to get all the child records from differen...   \n",
       "1  34554721  Retrieve all except some data of the another t...   \n",
       "2  34555135                                  Pandas: read_html   \n",
       "3  34555448                           Reader Always gimme NULL   \n",
       "4  34555752    php rearrange array elements based on condition   \n",
       "\n",
       "                                                Body  \\\n",
       "0  I am having 4 different tables like \\r\\nselect...   \n",
       "1  I have two table m_master and tbl_appointment\\...   \n",
       "2  <p>I'm trying to extract US states from wiki U...   \n",
       "3  I'm so new to C#, I wanna make an application ...   \n",
       "4  basically i have this array:\\r\\n\\r\\n    array(...   \n",
       "\n",
       "                                     Tags         CreationDate        Y  \n",
       "0                       <sql><sql-server>  2016-01-01 01:44:52  LQ_EDIT  \n",
       "1  <php><mysql><sql><codeigniter><mysqli>  2016-01-01 08:43:50  LQ_EDIT  \n",
       "2                        <python><pandas>  2016-01-01 09:55:22       HQ  \n",
       "3                    <sql-server><c#-4.0>  2016-01-01 10:43:45  LQ_EDIT  \n",
       "4                                   <php>  2016-01-01 11:34:09  LQ_EDIT  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('valid.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dataset.loc[dataset[\"Tags\"]==\"<python>\", \"Title\"]\n",
    "Y_train = dataset.loc[dataset[\"Tags\"]==\"<python>\", \"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19     i am new to pythn and was trying to fix indent...\n",
       "375                   Python syntax error in identation?\n",
       "481                                  Program doesn't run\n",
       "677    list index is out of range - cannot find why -...\n",
       "691                            Opening a .ipynb.txt File\n",
       "Name: Title, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19      LQ_EDIT\n",
       "375    LQ_CLOSE\n",
       "481    LQ_CLOSE\n",
       "677     LQ_EDIT\n",
       "691          HQ\n",
       "Name: Y, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for sentence in X_train:\n",
    "    tokenize_word = word_tokenize(sentence)\n",
    "    for word in tokenize_word:\n",
    "        all_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2888\n"
     ]
    }
   ],
   "source": [
    "print(len(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "871\n"
     ]
    }
   ],
   "source": [
    "unique_words = set(all_words)\n",
    "print(len(unique_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words \n",
    "(conversion of text to numerical form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorization function can convert text document to matrix of word count. The generated matrix is a sparsed matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# max_feature = 871 because 871 is the number of unique \n",
    "# words and we want these words to be converted to its numerical form.\n",
    "# min_df = 5 is because minimum number of document that should\n",
    "# include this feature.\n",
    "# max_df = 0.7 is because words that occur in max of 70% of all documents \n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=871, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "\n",
    "X = vectorizer.fit_transform(X_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=1000, random_state=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining the classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LQ_CLOSE', 'LQ_EDIT', 'LQ_CLOSE', 'LQ_CLOSE', 'LQ_EDIT',\n",
       "       'LQ_CLOSE', 'LQ_CLOSE', 'LQ_EDIT', 'LQ_CLOSE', 'LQ_CLOSE',\n",
       "       'LQ_CLOSE', 'LQ_EDIT', 'LQ_CLOSE', 'LQ_EDIT', 'LQ_EDIT',\n",
       "       'LQ_CLOSE', 'HQ', 'LQ_CLOSE', 'LQ_CLOSE', 'LQ_CLOSE', 'LQ_EDIT',\n",
       "       'LQ_EDIT', 'LQ_CLOSE', 'LQ_EDIT', 'LQ_CLOSE', 'LQ_CLOSE',\n",
       "       'LQ_CLOSE', 'LQ_CLOSE', 'LQ_CLOSE', 'LQ_CLOSE', 'LQ_CLOSE',\n",
       "       'LQ_CLOSE', 'LQ_CLOSE', 'LQ_EDIT', 'LQ_CLOSE', 'LQ_CLOSE',\n",
       "       'LQ_CLOSE', 'LQ_EDIT', 'LQ_CLOSE', 'LQ_CLOSE', 'LQ_EDIT',\n",
       "       'LQ_CLOSE', 'LQ_CLOSE', 'LQ_CLOSE', 'LQ_CLOSE', 'LQ_CLOSE',\n",
       "       'LQ_CLOSE', 'LQ_CLOSE', 'LQ_CLOSE', 'LQ_CLOSE', 'LQ_CLOSE',\n",
       "       'LQ_CLOSE', 'LQ_CLOSE', 'LQ_EDIT'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = classifier.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6296296296296297\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chat",
   "language": "python",
   "name": "chat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
